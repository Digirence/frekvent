#!/usr/bin/env python3
"""
Download Swedish ebooks and build a word frequency dictionary.
Cross-reference with the Swadesh 207-word list for Swedish.
"""

import os
import re
import time
import json
import requests
from collections import Counter
from urllib.parse import urljoin

# ---------------------------------------------------------------------------
# CONFIG
# ---------------------------------------------------------------------------
BOOKS_DIR = "swedish_books"
OUTPUT_FILE = "swedish_word_frequencies.txt"
SWADESH_OUTPUT = "swadesh_frequency_report.txt"
os.makedirs(BOOKS_DIR, exist_ok=True)

# ---------------------------------------------------------------------------
# SWEDISH BOOK SOURCES (Project Gutenberg plain text UTF-8)
# These are public-domain Swedish works available as plain text.
# ---------------------------------------------------------------------------
GUTENBERG_BOOKS = {
    # August Strindberg
    "RÃ¶da rummet": 57052,
    "HemsÃ¶borna": 30078,
    "Inferno": 29935,
    "GÃ¶tiska rummen": 48060,
    "Giftas I": 46012,
    "Giftas II": 46013,
    "Svenska Ã¶den och Ã¤ventyr I": 46096,
    "I havsbandet": 46035,
    "Utopier i verkligheten": 46176,
    "TjÃ¤nstekvinnans son I": 46008,
    # Selma LagerlÃ¶f
    "Bannlyst": 39147,
    "Kejsarn av Portugallien": 39087,
    "En herrgÃ¥rdssÃ¤gen": 39085,
    "Liljecronas hem": 39086,
    # Viktor Rydberg
    "Singoalla": 28610,
    "Den siste Atenaren I": 10117,
    "Den siste Atenaren II": 10504,
    "Vapensmeden": 11529,
    # Others
    "FolkungatrÃ¤det (Heidenstam)": 13371,
    "Det gÃ¥r an (Almqvist)": 14670,
    "Barnen ifrÃ¥n FrostmofjÃ¤llet": 9828,
    "Fritjofs Saga (TegnÃ©r)": 8518,
    "GÃ¶sta Berlings saga I": 28186,
    "GÃ¶sta Berlings saga II": 28188,
    "Nils Holgerssons underbara resa I": 36188,
    "Nils Holgerssons underbara resa II": 39772,
    "Pengar (Benedictsson)": 32608,
    "Familjen H*** (Knorring)": 40399,
    "Grannarne (Bremer)": 44099,
    "Hertha (Bremer)": 44098,
    "Drottningens juvelsmycke (Almqvist)": 24232,
    "Karolinerna I (Heidenstam)": 13370,
}

def download_gutenberg_text(book_id, title):
    """Download a Gutenberg book as plain text UTF-8."""
    filename = os.path.join(BOOKS_DIR, f"gutenberg_{book_id}.txt")
    if os.path.exists(filename) and os.path.getsize(filename) > 1000:
        print(f"  [cached] {title}")
        return filename

    # Gutenberg plain text URL patterns
    urls = [
        f"https://www.gutenberg.org/cache/epub/{book_id}/pg{book_id}.txt",
        f"https://www.gutenberg.org/files/{book_id}/{book_id}-0.txt",
        f"https://www.gutenberg.org/ebooks/{book_id}.txt.utf-8",
    ]

    for url in urls:
        try:
            resp = requests.get(url, timeout=30, headers={
                "User-Agent": "SwedishWordFrequency/1.0 (educational project)"
            })
            if resp.status_code == 200 and len(resp.text) > 1000:
                with open(filename, "w", encoding="utf-8") as f:
                    f.write(resp.text)
                print(f"  [downloaded] {title} ({len(resp.text):,} chars)")
                return filename
        except Exception as e:
            continue

    print(f"  [FAILED] {title} (id={book_id})")
    return None


def strip_gutenberg_header_footer(text):
    """Remove Project Gutenberg header and footer boilerplate."""
    # Find start of actual content
    start_markers = [
        "*** START OF THIS PROJECT GUTENBERG",
        "*** START OF THE PROJECT GUTENBERG",
        "***START OF THIS PROJECT GUTENBERG",
        "*** START OF THIS",
        "*END*THE SMALL PRINT",
    ]
    end_markers = [
        "*** END OF THIS PROJECT GUTENBERG",
        "*** END OF THE PROJECT GUTENBERG",
        "***END OF THIS PROJECT GUTENBERG",
        "*** END OF THIS",
        "End of Project Gutenberg",
        "End of the Project Gutenberg",
    ]

    for marker in start_markers:
        idx = text.find(marker)
        if idx != -1:
            nl = text.find("\n", idx)
            if nl != -1:
                text = text[nl + 1:]
            break

    for marker in end_markers:
        idx = text.find(marker)
        if idx != -1:
            text = text[:idx]
            break

    return text


# Common English-only words to filter out (not valid Swedish)
ENGLISH_STOPWORDS = {
    "the", "of", "a", "and", "to", "in", "that", "was", "he", "it",
    "his", "is", "with", "for", "as", "had", "her", "not", "but",
    "at", "be", "this", "have", "from", "or", "by", "which", "you",
    "an", "were", "are", "been", "has", "their", "said", "each",
    "she", "do", "its", "about", "would", "them", "made", "after",
    "could", "than", "been", "other", "into", "more", "some", "time",
    "very", "when", "come", "can", "no", "most", "only", "over",
    "such", "also", "back", "should", "well", "these", "where",
    "just", "we", "what", "your", "out", "if", "will", "up", "my",
    "who", "so", "they", "did", "him", "work", "any", "may", "then",
    "first", "all", "our", "free", "state", "one", "two", "way",
    "project", "gutenberg", "ebook", "license", "electronic",
    "works", "foundation", "terms", "copy", "distributed",
    "redistribution", "agreement", "trademark", "paragraph",
    "donations", "copyright", "permission", "archive", "donation",
    "volunteers", "compliance", "literary", "domain", "public",
    "refund", "replacement", "defect", "disclaimer", "warranties",
    "including", "limited", "warranties", "merchantability",
    "www", "http", "org", "htm", "txt", "utf",
}

# Words that exist in BOTH Swedish and English â€” keep these
SHARED_WORDS = {
    "i", "de", "en", "se", "man", "nu", "du", "vi", "den", "han",
    "hon", "sin", "an", "under", "in", "fort", "hand", "modern",
    "barn", "salt", "sand", "berg", "is", "fin", "hall", "full",
    "land", "rum", "folk", "arm", "form", "plan", "film", "ring",
    "start", "all", "organ", "rest", "lever", "horn", "mask",
    "nor", "plan", "order",
}


def extract_words(text):
    """Extract words from text, lowercased, preserving Swedish characters."""
    words = re.findall(r"[a-zÃ¥Ã¤Ã¶Ã©Ã¨Ã¼Ã¦Ã¸A-ZÃ…Ã„Ã–Ã‰ÃˆÃœÃ†Ã˜]+", text.lower())
    # Filter out very short or very long tokens, and English-only stopwords
    return [
        w for w in words
        if 1 <= len(w) <= 40
        and (w not in ENGLISH_STOPWORDS or w in SHARED_WORDS)
    ]


# ---------------------------------------------------------------------------
# SWADESH 207-WORD LIST FOR SWEDISH
# Standard linguistic core vocabulary list
# ---------------------------------------------------------------------------
SWADESH_SWEDISH = {
    # Pronouns
    "jag": "I", "du": "you (singular)", "han": "he", "hon": "she",
    "vi": "we", "ni": "you (plural)", "de": "they", "dem": "them",
    "den": "it/that", "det": "it/that (neuter)", "denna": "this",
    "detta": "this (neuter)", "hÃ¤r": "here", "dÃ¤r": "there",
    "vem": "who", "vad": "what", "var": "where", "nÃ¤r": "when",
    "hur": "how", "inte": "not", "alla": "all", "mÃ¥nga": "many",
    "nÃ¥gra": "some", "fÃ¥": "few", "andra": "other", "en": "one/a",
    "ett": "one/a (neuter)", "tvÃ¥": "two", "tre": "three", "fyra": "four",
    "fem": "five", "stor": "big", "lÃ¥ng": "long", "bred": "wide",
    "tjock": "thick", "tung": "heavy", "liten": "small", "kort": "short",
    "smal": "narrow", "tunn": "thin", "kvinna": "woman", "man": "man",
    "mÃ¤nniska": "human/person", "barn": "child", "hustru": "wife",
    "make": "husband", "mor": "mother", "far": "father",
    "djur": "animal", "fisk": "fish", "fÃ¥gel": "bird", "hund": "dog",
    "lus": "louse", "orm": "snake", "mask": "worm", "trÃ¤d": "tree",
    "skog": "forest", "kÃ¤pp": "stick", "frukt": "fruit", "frÃ¶": "seed",
    "blad": "leaf", "rot": "root", "bark": "bark (of tree)",
    "blomma": "flower", "grÃ¤s": "grass", "rep": "rope", "hud": "skin",
    "kÃ¶tt": "meat/flesh", "blod": "blood", "ben": "bone", "fett": "fat",
    "Ã¤gg": "egg", "horn": "horn", "svans": "tail", "fjÃ¤der": "feather",
    "hÃ¥r": "hair", "huvud": "head", "Ã¶ra": "ear", "Ã¶ga": "eye",
    "nÃ¤sa": "nose", "mun": "mouth", "tand": "tooth", "tunga": "tongue",
    "nagel": "fingernail", "fot": "foot", "knÃ¤": "knee", "hand": "hand",
    "vinge": "wing", "mage": "belly", "inÃ¤lvor": "guts", "hals": "neck",
    "rygg": "back", "brÃ¶st": "breast", "hjÃ¤rta": "heart",
    "lever": "liver", "dricka": "to drink", "Ã¤ta": "to eat",
    "bita": "to bite", "se": "to see", "hÃ¶ra": "to hear",
    "veta": "to know", "tÃ¤nka": "to think", "lukta": "to smell",
    "frukta": "to fear", "sova": "to sleep", "leva": "to live",
    "dÃ¶": "to die", "dÃ¶da": "to kill", "kÃ¤mpa": "to fight",
    "jaga": "to hunt", "slÃ¥": "to hit", "skÃ¤ra": "to cut",
    "dela": "to split", "sticka": "to stab", "klia": "to scratch",
    "grÃ¤va": "to dig", "simma": "to swim", "flyga": "to fly",
    "gÃ¥": "to walk", "komma": "to come", "ligga": "to lie down",
    "sitta": "to sit", "stÃ¥": "to stand", "vÃ¤nda": "to turn",
    "falla": "to fall", "ge": "to give", "hÃ¥lla": "to hold",
    "klÃ¤mma": "to squeeze", "gnida": "to rub", "tvÃ¤tta": "to wash",
    "torka": "to wipe", "dra": "to pull", "trycka": "to push",
    "kasta": "to throw", "binda": "to tie", "sy": "to sew",
    "rÃ¤kna": "to count", "sÃ¤ga": "to say", "sjunga": "to sing",
    "leka": "to play", "flyta": "to float", "flÃ¶da": "to flow",
    "frysa": "to freeze", "svÃ¤lla": "to swell", "sol": "sun",
    "mÃ¥ne": "moon", "stjÃ¤rna": "star", "vatten": "water", "regn": "rain",
    "flod": "river", "sjÃ¶": "lake", "hav": "sea", "salt": "salt",
    "sten": "stone", "sand": "sand", "stoft": "dust", "jord": "earth",
    "moln": "cloud", "dimma": "fog", "himmel": "sky", "vind": "wind",
    "snÃ¶": "snow", "is": "ice", "rÃ¶k": "smoke", "eld": "fire",
    "aska": "ash", "brÃ¤nna": "to burn", "vÃ¤g": "road/path",
    "berg": "mountain", "rÃ¶d": "red", "grÃ¶n": "green", "gul": "yellow",
    "vit": "white", "svart": "black", "natt": "night", "dag": "day",
    "Ã¥r": "year", "varm": "warm", "kall": "cold", "full": "full",
    "ny": "new", "gammal": "old", "god": "good", "dÃ¥lig": "bad",
    "rutten": "rotten", "smutsig": "dirty", "rak": "straight",
    "rund": "round", "vass": "sharp", "slÃ¶": "dull", "slÃ¤t": "smooth",
    "vÃ¥t": "wet", "torr": "dry", "rÃ¤tt": "right/correct",
    "nÃ¤ra": "near", "lÃ¥ngt": "far", "hÃ¶ger": "right",
    "vÃ¤nster": "left", "vid": "at/by", "i": "in", "med": "with",
    "och": "and", "om": "if/about", "fÃ¶r": "for/because",
    "namn": "name", "sÃ¤ga": "to say",
    # Additional high-value forms
    "vara": "to be", "ha": "to have", "bli": "to become",
    "ska": "shall/will", "kan": "can", "mÃ¥ste": "must",
    "ville": "wanted", "skulle": "would", "hade": "had",
    "var": "was/where", "Ã¤r": "is/am/are", "blev": "became",
    "finns": "exists/there is", "sig": "oneself", "sin": "his/her (own)",
    "sitt": "his/her (own, neuter)", "sina": "his/her (own, plural)",
    "min": "my", "mitt": "my (neuter)", "din": "your",
    "hans": "his", "hennes": "her", "som": "who/which/that",
    "att": "to/that", "av": "of/from", "pÃ¥": "on/at",
    "till": "to", "frÃ¥n": "from", "ut": "out", "upp": "up",
    "ner": "down", "Ã¶ver": "over", "under": "under",
    "mellan": "between", "efter": "after", "fÃ¶re": "before",
    "genom": "through", "hos": "at (someone's place)",
    "mot": "towards/against", "utan": "without",
    "ocksÃ¥": "also", "redan": "already", "bara": "only/just",
    "nog": "enough/probably", "mycket": "much/very",
    "mer": "more", "mest": "most", "sedan": "since/then",
    "nu": "now", "aldrig": "never", "alltid": "always",
    "ja": "yes", "nej": "no",
}


# ---------------------------------------------------------------------------
# MAIN
# ---------------------------------------------------------------------------
def main():
    print("=" * 60)
    print("SWEDISH EBOOK WORD FREQUENCY ANALYZER")
    print("=" * 60)

    # --- Phase 1: Download books ---
    print(f"\nðŸ“¥ Downloading {len(GUTENBERG_BOOKS)} Swedish books from Project Gutenberg...\n")
    downloaded_files = []
    for title, book_id in GUTENBERG_BOOKS.items():
        filepath = download_gutenberg_text(book_id, title)
        if filepath:
            downloaded_files.append((title, filepath))
        time.sleep(0.5)  # Be polite to servers

    print(f"\nâœ… Successfully downloaded {len(downloaded_files)} / {len(GUTENBERG_BOOKS)} books")

    # --- Phase 2: Extract words ---
    print(f"\nðŸ“– Extracting words from {len(downloaded_files)} books...\n")
    total_counter = Counter()
    book_stats = []

    for title, filepath in downloaded_files:
        with open(filepath, "r", encoding="utf-8", errors="replace") as f:
            text = f.read()

        text = strip_gutenberg_header_footer(text)
        words = extract_words(text)
        total_counter.update(words)
        book_stats.append((title, len(words)))
        print(f"  {title}: {len(words):,} words")

    total_words = sum(total_counter.values())
    unique_words = len(total_counter)
    print(f"\nðŸ“Š Total words: {total_words:,}")
    print(f"ðŸ“Š Unique words: {unique_words:,}")

    # --- Phase 3: Save full frequency dictionary ---
    print(f"\nðŸ’¾ Saving frequency dictionary to {OUTPUT_FILE}...")
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(f"# Swedish Word Frequency Dictionary\n")
        f.write(f"# Generated from {len(downloaded_files)} Swedish ebooks\n")
        f.write(f"# Total words: {total_words:,}\n")
        f.write(f"# Unique words: {unique_words:,}\n")
        f.write(f"# Format: word<TAB>frequency\n")
        f.write(f"#\n")
        f.write(f"# Books analyzed:\n")
        for title, wc in book_stats:
            f.write(f"#   - {title} ({wc:,} words)\n")
        f.write(f"#\n")
        f.write(f"# {'='*50}\n\n")

        for word, freq in total_counter.most_common():
            f.write(f"{word}\t{freq}\n")

    print(f"  âœ… Saved {unique_words:,} entries")

    # --- Phase 4: Swadesh cross-reference ---
    print(f"\nðŸ”¤ Cross-referencing with Swadesh list ({len(SWADESH_SWEDISH)} entries)...\n")

    swadesh_freqs = []
    for sv_word, en_meaning in SWADESH_SWEDISH.items():
        freq = total_counter.get(sv_word, 0)
        swadesh_freqs.append((sv_word, en_meaning, freq))

    # Sort by frequency descending
    swadesh_freqs.sort(key=lambda x: x[2], reverse=True)

    with open(SWADESH_OUTPUT, "w", encoding="utf-8") as f:
        f.write("# Swadesh Core Vocabulary - Frequency in Swedish Literature\n")
        f.write(f"# Based on {len(downloaded_files)} Swedish ebooks ({total_words:,} total words)\n")
        f.write(f"# Sorted by frequency (most common first)\n")
        f.write(f"#\n")
        f.write(f"# STRATEGY: Learn the top words first â€” they cover the most text.\n")
        f.write(f"# The top 50 Swadesh words alone will cover a huge chunk of any Swedish text.\n")
        f.write(f"#\n")
        f.write(f"# {'='*70}\n")
        f.write(f"# {'Rank':<6}{'Swedish':<15}{'English':<25}{'Frequency':<12}{'% of text'}\n")
        f.write(f"# {'='*70}\n\n")

        for rank, (sv, en, freq) in enumerate(swadesh_freqs, 1):
            pct = (freq / total_words * 100) if total_words > 0 else 0
            f.write(f"{rank:<6}{sv:<15}{en:<25}{freq:<12}{pct:.4f}%\n")

        # Summary statistics
        f.write(f"\n\n# {'='*70}\n")
        f.write(f"# LEARNING PRIORITY TIERS\n")
        f.write(f"# {'='*70}\n\n")

        # Tier 1: top 50
        f.write("## TIER 1 â€” Learn First (Top 50 by frequency)\n")
        f.write("## These words appear most often in real Swedish text.\n\n")
        cumulative = 0
        for rank, (sv, en, freq) in enumerate(swadesh_freqs[:50], 1):
            pct = (freq / total_words * 100) if total_words > 0 else 0
            cumulative += pct
            f.write(f"  {rank:>3}. {sv:<15} = {en:<25} ({freq:>8,}x, {pct:.3f}%)\n")
        f.write(f"\n  â†’ These 50 words cover {cumulative:.1f}% of all text!\n")

        # Tier 2: 51-100
        f.write(f"\n## TIER 2 â€” Learn Next (Rank 51-100)\n\n")
        for rank, (sv, en, freq) in enumerate(swadesh_freqs[50:100], 51):
            pct = (freq / total_words * 100) if total_words > 0 else 0
            cumulative += pct
            f.write(f"  {rank:>3}. {sv:<15} = {en:<25} ({freq:>8,}x, {pct:.3f}%)\n")
        f.write(f"\n  â†’ Top 100 words cover {cumulative:.1f}% of all text!\n")

        # Tier 3: rest
        f.write(f"\n## TIER 3 â€” Learn Later (Rank 101+)\n\n")
        for rank, (sv, en, freq) in enumerate(swadesh_freqs[100:], 101):
            pct = (freq / total_words * 100) if total_words > 0 else 0
            f.write(f"  {rank:>3}. {sv:<15} = {en:<25} ({freq:>8,}x, {pct:.3f}%)\n")

    print(f"  âœ… Saved Swadesh report to {SWADESH_OUTPUT}")

    # --- Print top 30 Swadesh words to console ---
    print(f"\n{'='*70}")
    print("TOP 30 SWADESH WORDS BY FREQUENCY IN SWEDISH LITERATURE")
    print(f"{'='*70}")
    print(f"{'Rank':<6}{'Swedish':<15}{'English':<25}{'Frequency':<12}")
    print("-" * 58)
    for rank, (sv, en, freq) in enumerate(swadesh_freqs[:30], 1):
        print(f"{rank:<6}{sv:<15}{en:<25}{freq:<12,}")

    # --- Print overall top 30 words ---
    print(f"\n{'='*70}")
    print("TOP 30 MOST COMMON WORDS IN SWEDISH LITERATURE (ALL)")
    print(f"{'='*70}")
    for rank, (word, freq) in enumerate(total_counter.most_common(30), 1):
        en = SWADESH_SWEDISH.get(word, "")
        tag = f" ({en})" if en else ""
        print(f"  {rank:>3}. {word:<15} {freq:>10,}{tag}")

    print(f"\nðŸŽ‰ Done! Check these files:")
    print(f"   ðŸ“„ {OUTPUT_FILE} â€” Full frequency dictionary ({unique_words:,} words)")
    print(f"   ðŸ“„ {SWADESH_OUTPUT} â€” Swadesh learning priority guide")


if __name__ == "__main__":
    main()
